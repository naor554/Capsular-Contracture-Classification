{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from monai.transforms import Compose, EnsureChannelFirstd, ScaleIntensityd, ResizeD, ToTensord,LoadImaged, RandFlipd, RandRotated, RandGaussianNoised\n",
    "from monai.data import Dataset, DataLoader, NumpyReader\n",
    "from monai.networks.nets import resnet18\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import csv\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    roc_curve,\n",
    "    roc_auc_score\n",
    ")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Define data transformations for data augmentation and normalization\n",
    "train_transforms = Compose([\n",
    "    LoadImaged(keys=[\"image\"], reader=NumpyReader),\n",
    "    EnsureChannelFirstd(keys=[\"image\"]),\n",
    "    ResizeD(keys=[\"image\"], spatial_size=(128, 128, 32)),\n",
    "    ScaleIntensityd(keys=[\"image\"]),\n",
    "    RandFlipd(keys=[\"image\"], prob=0.5, spatial_axis=0),\n",
    "    RandRotated(keys=[\"image\"], range_x=0.1, range_y=0.1, range_z=0.1, prob=0.5),\n",
    "    RandGaussianNoised(keys=[\"image\"], prob=0.1, mean=0.0, std=0.1),\n",
    "    ToTensord(keys=[\"image\", \"label\"]),\n",
    "])\n",
    "\n",
    "val_transforms = Compose([\n",
    "    LoadImaged(keys=[\"image\"], reader=NumpyReader),\n",
    "    EnsureChannelFirstd(keys=[\"image\"]),\n",
    "    ResizeD(keys=[\"image\"], spatial_size=(128, 128, 32)),\n",
    "    ScaleIntensityd(keys=[\"image\"]),\n",
    "    ToTensord(keys=[\"image\", \"label\"]),\n",
    "])"
   ],
   "id": "6385b2f6bed72502"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "csv_file = \"data_labels.csv\"  # your CSV file\n",
    "\n",
    "all_items = []\n",
    "with open(csv_file, \"r\") as f:\n",
    "    reader = csv.DictReader(f)  # expects columns: image, label\n",
    "    for row in reader:\n",
    "        image_path = row[\"image\"]\n",
    "        label = int(row[\"label\"])\n",
    "        all_items.append({\"image\": image_path, \"label\": label})\n",
    "\n",
    "# Shuffle the entire dataset\n",
    "random.shuffle(all_items)"
   ],
   "id": "368912112f764937"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Define K-Fold Cross Validation\n",
    "k = 5\n",
    "kf = KFold(n_splits=k, shuffle=True, random_state=42)"
   ],
   "id": "d8d2c514d66366ed"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Use GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load the pre-trained 3dResNet-18 model\n",
    "model = resnet18(\n",
    "    spatial_dims=3,\n",
    "    n_input_channels=1,\n",
    "    num_classes=2\n",
    ").to(device)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)"
   ],
   "id": "973722f41216c227"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Store final results\n",
    "all_y_true, all_y_pred, all_y_prob = [], [], []\n",
    "final_metrics = {}"
   ],
   "id": "33570ecbf27eca"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Perform K-Fold Cross Validation\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(all_items)):\n",
    "    print(f\"\\nðŸ”¹ Starting Fold {fold + 1}/{k}\")\n",
    "\n",
    "    train_subset = [all_items[i] for i in train_idx]\n",
    "    val_subset = [all_items[i] for i in val_idx]\n",
    "\n",
    "    train_ds = Dataset(train_subset, transform=train_transforms)\n",
    "    val_ds = Dataset(val_subset, transform=val_transforms)\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=8, shuffle=True)\n",
    "    val_loader = DataLoader(val_ds, batch_size=8, shuffle=False)\n",
    "\n",
    "    # Training and validation loop\n",
    "    num_epochs = 10\n",
    "    fold_train_loss, fold_val_loss = [], []\n",
    "    y_true_fold, y_pred_fold, y_prob_fold = [], [], []\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        for batch in train_loader:\n",
    "            images, labels = batch[\"image\"], batch[\"label\"]\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "        avg_train_loss = epoch_loss / len(train_loader)\n",
    "        fold_train_loss.append(avg_train_loss)\n",
    "        print(f\"Epoch {epoch + 1}, Train Loss: {avg_train_loss:.4f}\")\n",
    "        \n",
    "        # Validation after every epoch\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                images, labels = batch[\"image\"], batch[\"label\"]\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                probs = torch.softmax(outputs, dim=1)[:, 1]  # Probability of class \"1\"\n",
    "                preds = torch.argmax(outputs, dim=1)\n",
    "                y_true_fold.extend(labels.cpu().numpy())\n",
    "                y_pred_fold.extend(preds.cpu().numpy())\n",
    "                y_prob_fold.extend(probs.cpu().numpy())\n",
    "        \n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        fold_val_loss.append(avg_val_loss)\n",
    "        print(f\"Val Loss: {avg_val_loss:.4f}\")\n",
    "    \n",
    "    final_metrics[\"train_loss\"].append(np.mean(fold_train_loss))\n",
    "    final_metrics[\"val_loss\"].append(np.mean(fold_val_loss))\n",
    "    all_y_true.extend(y_true_fold)\n",
    "    all_y_pred.extend(y_pred_fold)\n",
    "    all_y_prob.extend(y_prob_fold)"
   ],
   "id": "7db2a24b04038e31"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(all_y_true, all_y_pred)\n",
    "\n",
    "# Calculate metrics\n",
    "acc = accuracy_score(all_y_true, all_y_pred)\n",
    "prec = precision_score(all_y_true, all_y_pred)\n",
    "rec = recall_score(all_y_true, all_y_pred)\n",
    "f1 = f1_score(all_y_true, all_y_pred)\n",
    "\n",
    "# For ROC-AUC, we need probabilities for the positive class\n",
    "fpr, tpr, thresholds = roc_curve(all_y_true, all_y_prob)\n",
    "roc_auc = roc_auc_score(all_y_true, all_y_prob)\n",
    "\n",
    "print(\"\\n========== Final Evaluation on Validation Set ==========\")\n",
    "print(\"Confusion Matrix:\\n\", cm)\n",
    "print(f\"Accuracy:    {acc:.4f}\")\n",
    "print(f\"Precision:   {prec:.4f}\")\n",
    "print(f\"Recall:      {rec:.4f}\")\n",
    "print(f\"F1-Score:    {f1:.4f}\")\n",
    "print(f\"ROC-AUC:     {roc_auc:.4f}\")"
   ],
   "id": "29d86392e5f8aad3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Display the results\n",
    "plt.figure(figsize=(5, 4))\n",
    "sns.heatmap(cm, annot=True, cmap=\"Blues\", fmt=\"d\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()\n",
    "\n",
    "# Plot the ROC curve\n",
    "plt.figure(figsize=(5, 4))\n",
    "plt.plot(fpr, tpr, label=f\"ROC curve (AUC={roc_auc:.2f})\", color=\"blue\")\n",
    "plt.plot([0, 1], [0, 1], \"r--\", label=\"Random Classifier\")\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1.05])\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ],
   "id": "2724307d42045f13"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
