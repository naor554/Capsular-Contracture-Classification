{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from monai.transforms import Compose, EnsureChannelFirstd, ScaleIntensityd, ResizeD, ToTensord,LoadImaged\n",
    "from monai.data import Dataset, DataLoader, NumpyReader\n",
    "from monai.networks.nets import resnet18\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import csv\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    roc_curve,\n",
    "    roc_auc_score\n",
    ")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Define data transformations for data augmentation and normalization\n",
    "train_transforms = Compose([\n",
    "    LoadImaged(keys=[\"image\"], reader=NumpyReader),\n",
    "    EnsureChannelFirstd(keys=[\"image\"]),\n",
    "    ResizeD(keys=[\"image\"], spatial_size=(128, 128, 32)),\n",
    "    ScaleIntensityd(keys=[\"image\"]),\n",
    "    ToTensord(keys=[\"image\", \"label\"]),\n",
    "])\n",
    "\n",
    "val_transforms = Compose([\n",
    "    LoadImaged(keys=[\"image\"], reader=NumpyReader),\n",
    "    EnsureChannelFirstd(keys=[\"image\"]),\n",
    "    ResizeD(keys=[\"image\"], spatial_size=(128, 128, 32)),\n",
    "    ScaleIntensityd(keys=[\"image\"]),\n",
    "    ToTensord(keys=[\"image\", \"label\"]),\n",
    "])"
   ],
   "id": "6385b2f6bed72502"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "csv_file = \"data_paths_labels.csv\"  # your CSV file\n",
    "\n",
    "all_items = []\n",
    "with open(csv_file, \"r\") as f:\n",
    "    reader = csv.DictReader(f)  # expects columns: image, label\n",
    "    for row in reader:\n",
    "        image_path = row[\"image\"]\n",
    "        label = int(row[\"label\"])\n",
    "        all_items.append({\"image\": image_path, \"label\": label})\n",
    "\n",
    "# Shuffle the entire dataset\n",
    "random.shuffle(all_items)"
   ],
   "id": "368912112f764937"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Define split ratios\n",
    "train_ratio = 0.8\n",
    "val_ratio = 0.2\n",
    "\n",
    "# Calculate sizes\n",
    "data_size = len(all_items)\n",
    "train_size = int(train_ratio * data_size)\n",
    "val_size = int(val_ratio * data_size)\n",
    "\n",
    "# Split dataset\n",
    "train_list = all_items[:train_size]\n",
    "val_list = all_items[train_size: train_size + val_size]\n",
    "\n",
    "print(\"Train:\", len(train_list), \"Validation:\", len(val_list))"
   ],
   "id": "d8d2c514d66366ed"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create data sets and data loaders\n",
    "train_ds = Dataset(data=train_list, transform=train_transforms)\n",
    "val_ds = Dataset(data=val_list, transform=val_transforms)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=1, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_ds, batch_size=1, shuffle=False, num_workers=2)"
   ],
   "id": "97cd8c10bb87979"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Use GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load the pre-trained 3dResNet-18 model\n",
    "model = resnet18(\n",
    "    spatial_dims=3,\n",
    "    n_input_channels=1,\n",
    "    num_classes=2\n",
    ").to(device)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)"
   ],
   "id": "973722f41216c227"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "max_epochs = 10\n",
    "for epoch in range(max_epochs):\n",
    "    # Training\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for batch in train_loader:\n",
    "        images = batch[\"image\"].to(device)\n",
    "        labels = batch[\"label\"].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    train_loss /= len(train_loader)\n",
    "    print(f\"Epoch [{epoch+1}/{max_epochs}], Train Loss: {train_loss:.4f}\")\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            images = batch[\"image\"].to(device)\n",
    "            labels = batch[\"label\"].to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs, dim=1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    val_loss /= len(val_loader)\n",
    "    accuracy = correct / total\n",
    "    print(f\"Validation Loss: {val_loss:.4f}, Accuracy: {accuracy:.4f}\\n\")\n"
   ],
   "id": "7db2a24b04038e31"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Final Evaluation: Confusion Matrix, Metrics, and Plots\n",
    "model.eval()\n",
    "y_true = []\n",
    "y_pred = []\n",
    "y_prob = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for val_data in val_loader:\n",
    "        val_images = val_data[\"image\"].to(device)\n",
    "        val_labels = val_data[\"label\"].to(device)\n",
    "\n",
    "        outputs = model(val_images)  # shape [B, 2]\n",
    "        probs = torch.softmax(outputs, dim=1)[:, 1]  # probability of class \"1\"\n",
    "\n",
    "        _, predicted_labels = torch.max(outputs, dim=1)\n",
    "\n",
    "        y_true.extend(val_labels.cpu().numpy().tolist())\n",
    "        y_pred.extend(predicted_labels.cpu().numpy().tolist())\n",
    "        y_prob.extend(probs.cpu().numpy().tolist())\n",
    "\n",
    "y_true = np.array(y_true)\n",
    "y_pred = np.array(y_pred)\n",
    "y_prob = np.array(y_prob)\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Calculate metrics\n",
    "acc = accuracy_score(y_true, y_pred)\n",
    "prec = precision_score(y_true, y_pred, zero_division=0)\n",
    "rec = recall_score(y_true, y_pred, zero_division=0)\n",
    "f1 = f1_score(y_true, y_pred, zero_division=0)\n",
    "\n",
    "# For ROC-AUC, we need probabilities for the positive class\n",
    "fpr, tpr, thresholds = roc_curve(y_true, y_prob)\n",
    "roc_auc = roc_auc_score(y_true, y_prob)\n",
    "\n",
    "print(\"\\n========== Final Evaluation on Validation Set ==========\")\n",
    "print(\"Confusion Matrix:\\n\", cm)\n",
    "print(f\"Accuracy:    {acc:.4f}\")\n",
    "print(f\"Precision:   {prec:.4f}\")\n",
    "print(f\"Recall:      {rec:.4f}\")\n",
    "print(f\"F1-Score:    {f1:.4f}\")\n",
    "print(f\"ROC-AUC:     {roc_auc:.4f}\")"
   ],
   "id": "29d86392e5f8aad3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Display the results\n",
    "plt.figure(figsize=(5, 4))\n",
    "sns.heatmap(cm, annot=True, cmap=\"Blues\", fmt=\"d\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()\n",
    "\n",
    "# Plot the ROC curve\n",
    "plt.figure(figsize=(5, 4))\n",
    "plt.plot(fpr, tpr, label=f\"ROC curve (AUC={roc_auc:.2f})\", color=\"blue\")\n",
    "plt.plot([0, 1], [0, 1], \"r--\", label=\"Random Classifier\")\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1.05])\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ],
   "id": "2724307d42045f13"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
